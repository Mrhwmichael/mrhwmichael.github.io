<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>使用Keras搭建NLP自然语言处理模型 - why&#039;s Blog</title><meta description="本篇博文承担了我在GitHub的开源代码的相关注解，这里给我的Github工程做一个简单的阐释。 代码话不多说，先放代码。我将主要内容放进注释中，逻辑还是比较清晰的，通过keras实现了双向LSTM和CNN。"><meta property="og:type" content="blog"><meta property="og:title" content="使用Keras搭建NLP自然语言处理模型"><meta property="og:url" content="http://yoursite.com/2019/11/27/%E4%BD%BF%E7%94%A8Keras%E6%90%AD%E5%BB%BANLP%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/"><meta property="og:site_name" content="why&#039;s Blog"><meta property="og:description" content="本篇博文承担了我在GitHub的开源代码的相关注解，这里给我的Github工程做一个简单的阐释。 代码话不多说，先放代码。我将主要内容放进注释中，逻辑还是比较清晰的，通过keras实现了双向LSTM和CNN。"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:published_time" content="2019-11-27T11:06:46.000Z"><meta property="article:modified_time" content="2020-08-12T16:08:38.543Z"><meta property="article:author" content="Michael Wang"><meta property="article:tag" content="keras"><meta property="article:tag" content="tensorflow"><meta property="article:tag" content="nlp"><meta property="article:tag" content="自然语言处理"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com/2019/11/27/%E4%BD%BF%E7%94%A8Keras%E6%90%AD%E5%BB%BANLP%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/"},"headline":"why's Blog","image":["http://yoursite.com/img/og_image.png"],"datePublished":"2019-11-27T11:06:46.000Z","dateModified":"2020-08-12T16:08:38.543Z","author":{"@type":"Person","name":"Michael Wang"},"description":"本篇博文承担了我在GitHub的开源代码的相关注解，这里给我的Github工程做一个简单的阐释。 代码话不多说，先放代码。我将主要内容放进注释中，逻辑还是比较清晰的，通过keras实现了双向LSTM和CNN。"}</script><link rel="canonical" href="http://yoursite.com/2019/11/27/%E4%BD%BF%E7%94%A8Keras%E6%90%AD%E5%BB%BANLP%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="why&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Mrhwmichael/"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2019-11-27T11:06:46.000Z" title="2019-11-27T11:06:46.000Z">2019-11-27</time><span class="level-item">7 minutes read (About 1024 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">使用Keras搭建NLP自然语言处理模型</h1><div class="content"><p>本篇博文承担了我在GitHub的开源代码的相关注解，这里给我的Github工程做一个简单的阐释。</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>话不多说，先放代码。我将主要内容放进注释中，逻辑还是比较清晰的，通过keras实现了双向LSTM和CNN。</p>
 <a id="more"></a> 

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding：utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> keras_preprocessing <span class="keyword">import</span> sequence</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras <span class="keyword">as</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置相关维度，这里统一收敛到这里</span></span><br><span class="line">MAX_DOCUMENT_LEN = <span class="number">300</span></span><br><span class="line">TRAINING_SIZE = <span class="number">120000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用训练的word2Vec的词向量的配置</span></span><br><span class="line">myPath = <span class="string">'ml_resources/Word2VecModel.vector'</span></span><br><span class="line">Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(myPath)</span><br><span class="line">EMBEDDING_SIZE = <span class="number">128</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用腾讯70000词的词向量的配置</span></span><br><span class="line"><span class="comment"># myPath = 'ml_resources/70000_tencent.vector'</span></span><br><span class="line"><span class="comment"># Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(myPath)</span></span><br><span class="line"><span class="comment"># EMBEDDING_SIZE = 200</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造包含所有词语的 list，以及初始化 “词语-序号”字典 和 “词向量”矩阵</span></span><br><span class="line">vocab_list = [word <span class="keyword">for</span> word, Vocab <span class="keyword">in</span> Word2VecModel.wv.vocab.items()]  <span class="comment"># 存储 所有的 词语</span></span><br><span class="line"></span><br><span class="line">word_index = &#123;<span class="string">" "</span>: <span class="number">0</span>&#125;  <span class="comment"># 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。  “词语-序号”字典</span></span><br><span class="line">word_vector = &#123;&#125;  <span class="comment"># 初始化`[word : vector]`字典</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化存储所有向量的大矩阵，留意其中多一位（首行），词向量全为 0，用于 padding补零。</span></span><br><span class="line"><span class="comment"># 行数为所有单词数+1</span></span><br><span class="line">embeddings_matrix = np.zeros((len(vocab_list) + <span class="number">1</span>, Word2VecModel.vector_size))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填充上述的字典和大矩阵</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(vocab_list)):</span><br><span class="line">    <span class="comment"># print(i)</span></span><br><span class="line">    word = vocab_list[i]  <span class="comment"># 每个词语</span></span><br><span class="line">    word_index[word] = i + <span class="number">1</span> <span class="comment"># 词语：序号</span></span><br><span class="line">    word_vector[word] = Word2VecModel.wv[word] <span class="comment"># 词语：词向量</span></span><br><span class="line">    embeddings_matrix[i + <span class="number">1</span>] = Word2VecModel.wv[word]  <span class="comment"># 词向量矩阵</span></span><br><span class="line"><span class="comment"># print(embeddings_matrix.shape)</span></span><br><span class="line"><span class="comment"># print(word_index) # 查看大字典内容</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 目前生成六个内容，分别是label标签，总评score，星级别star1，star2，star3</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_csv</span><span class="params">(filename)</span>:</span></span><br><span class="line">    content = []</span><br><span class="line">    label = []</span><br><span class="line">    score = []</span><br><span class="line">    star1 = []</span><br><span class="line">    star2 = []</span><br><span class="line">    star3 = []</span><br><span class="line">    <span class="keyword">with</span> open(filename, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> csvDataFile:</span><br><span class="line">        csvReader = csv.reader((line.replace(<span class="string">'\0'</span>, <span class="string">''</span>) <span class="keyword">for</span> line <span class="keyword">in</span> csvDataFile),  delimiter=<span class="string">','</span>)</span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> csvReader:</span><br><span class="line">            <span class="keyword">if</span> len(row)&lt;<span class="number">5</span>:</span><br><span class="line">                print(row)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                content.append(row[<span class="number">0</span>])</span><br><span class="line">                label.append(row[<span class="number">1</span>])</span><br><span class="line">                score.append(row[<span class="number">2</span>])</span><br><span class="line">                star1.append(row[<span class="number">3</span>])</span><br><span class="line">                star2.append(row[<span class="number">4</span>])</span><br><span class="line">                star3.append(row[<span class="number">5</span>])</span><br><span class="line">    print(len(content))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="number">100</span>)</span><br><span class="line">    np.random.shuffle(content)</span><br><span class="line">    np.random.seed(<span class="number">100</span>)</span><br><span class="line">    np.random.shuffle(label)</span><br><span class="line">    np.random.seed(<span class="number">100</span>)</span><br><span class="line">    np.random.shuffle(score)</span><br><span class="line">    np.random.seed(<span class="number">100</span>)</span><br><span class="line">    np.random.shuffle(star1)</span><br><span class="line">    np.random.seed(<span class="number">100</span>)</span><br><span class="line">    np.random.shuffle(star2)</span><br><span class="line">    np.random.seed(<span class="number">100</span>)</span><br><span class="line">    np.random.shuffle(star3)</span><br><span class="line"></span><br><span class="line">    X = np.asarray(content[<span class="number">0</span>:TRAINING_SIZE])</span><br><span class="line">    Y = np.asarray(label[<span class="number">0</span>:TRAINING_SIZE], dtype=int)</span><br><span class="line">    A = np.asarray(score[<span class="number">0</span>:TRAINING_SIZE], dtype=int)</span><br><span class="line">    B = np.asarray(star1[<span class="number">0</span>:TRAINING_SIZE], dtype=int)</span><br><span class="line">    C = np.asarray(star2[<span class="number">0</span>:TRAINING_SIZE], dtype=int)</span><br><span class="line">    D = np.asarray(star3[<span class="number">0</span>:TRAINING_SIZE], dtype=int)</span><br><span class="line">    <span class="keyword">return</span> X, Y, A, B, C, D</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X_train, Y_train, score, star1, star2, star3 = read_csv(<span class="string">'ml_resources/training_data_set.csv'</span>)</span><br><span class="line">print(Y_train.mean()) <span class="comment"># 统计数据集中1的占比</span></span><br><span class="line">behavior_input = np.concatenate((score.reshape(<span class="number">-1</span>,<span class="number">1</span>), star1.reshape(<span class="number">-1</span>,<span class="number">1</span>), star2.reshape(<span class="number">-1</span>,<span class="number">1</span>), star3.reshape(<span class="number">-1</span>,<span class="number">1</span>)), axis=<span class="number">1</span>)</span><br><span class="line">print(behavior_input)</span><br><span class="line"><span class="comment"># X_test, Y_test = read_csv('little_test.csv')</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span><span class="params">(texts, word_index)</span>:</span></span><br><span class="line">    data = []</span><br><span class="line">    maxnum = MAX_DOCUMENT_LEN</span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> texts:</span><br><span class="line">        new_txt = []</span><br><span class="line">        sentence = re.sub(<span class="string">"[\s+\.\!\/_,$%^*(+\"\']+|[+——！，。？、~@#￥%……&amp;*（）]+"</span>, <span class="string">""</span>, sentence)</span><br><span class="line">        sentence = jieba.lcut(sentence)</span><br><span class="line">        <span class="comment"># print(sentence)</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> sentence:</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            <span class="comment"># print(word)</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                new_txt.append(word_index[word])</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                new_txt.append(<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># print(new_txt)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i &gt; maxnum:</span><br><span class="line">            <span class="comment"># print(new_txt)</span></span><br><span class="line">            maxnum = i</span><br><span class="line">        data.append(new_txt)</span><br><span class="line">    texts = sequence.pad_sequences(data, maxlen=MAX_DOCUMENT_LEN)</span><br><span class="line">    print(<span class="string">'&#123;&#125; &#123;&#125;'</span>.format(<span class="string">'max'</span>, maxnum))</span><br><span class="line">    <span class="keyword">return</span> texts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X_train = tokenizer(X_train, word_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打乱</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">np.random.shuffle(X_train)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">np.random.shuffle(Y_train)</span><br><span class="line"></span><br><span class="line">print(X_train)</span><br><span class="line">print(Y_train)</span><br><span class="line">print(X_train.shape, <span class="string">' '</span>, Y_train.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主训练模型部分</span></span><br><span class="line">input1 = keras.Input(shape=(MAX_DOCUMENT_LEN,))</span><br><span class="line">embedding = layers.Embedding(len(word_index), EMBEDDING_SIZE, input_length=MAX_DOCUMENT_LEN, embeddings_initializer=keras.initializers.Constant(embeddings_matrix))(input1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用RNN模型训练部分（结果为x）</span></span><br><span class="line">x = layers.Bidirectional(layers.LSTM(<span class="number">128</span>, return_sequences=<span class="literal">True</span>))(embedding)</span><br><span class="line">x = layers.Bidirectional(layers.LSTM(<span class="number">64</span>))(x)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">x = layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用CNN模型训练部分（结果为y）</span></span><br><span class="line">filters = <span class="number">250</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line">hidden_dims = <span class="number">250</span></span><br><span class="line">max_features = <span class="number">400000</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># y = layers.Dropout(0.2)(embedding)</span></span><br><span class="line"><span class="comment"># y = layers.Conv1D(filters,</span></span><br><span class="line"><span class="comment">#                  kernel_size,</span></span><br><span class="line"><span class="comment">#                  padding='valid',</span></span><br><span class="line"><span class="comment">#                  activation='relu',</span></span><br><span class="line"><span class="comment">#                  strides=1)(y)</span></span><br><span class="line"><span class="comment"># # we use max pooling:</span></span><br><span class="line"><span class="comment"># y = layers.GlobalMaxPooling1D()(y)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># # We add a vanilla hidden layer:</span></span><br><span class="line"><span class="comment"># y = layers.Dense(hidden_dims)(y)</span></span><br><span class="line"><span class="comment"># y = layers.Dropout(0.2)(y)</span></span><br><span class="line"><span class="comment"># y = layers.Activation('relu')(y)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># # We project onto a single unit output layer, and squash it with a sigmoid:</span></span><br><span class="line"><span class="comment"># y = layers.Dense(1)(y)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># # 连接CNN和RNN模型</span></span><br><span class="line"><span class="comment"># input2 = keras.Input(shape=(1,))</span></span><br><span class="line"><span class="comment"># x = keras.layers.concatenate([x, input2])</span></span><br><span class="line"><span class="comment"># x = layers.Dense(2, activation='relu')(x)</span></span><br><span class="line"><span class="comment"># output_tensor = layers.Dense(1, activation='sigmoid')(x)</span></span><br><span class="line">model = keras.Model(input1, x)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(),</span><br><span class="line">              loss=keras.losses.binary_crossentropy,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型可视化</span></span><br><span class="line"></span><br><span class="line">history = model.fit(X_train, Y_train, batch_size=<span class="number">128</span>, epochs=<span class="number">5</span>, validation_split=<span class="number">0.05</span>, callbacks=[keras.callbacks.TensorBoard(log_dir=<span class="string">'result'</span>)])</span><br><span class="line"></span><br><span class="line">model.save(<span class="string">"TrainResult_full.h5"</span>)</span><br></pre></td></tr></table></figure>

</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/keras/">keras</a><a class="link-muted mr-2" rel="tag" href="/tags/tensorflow/">tensorflow</a><a class="link-muted mr-2" rel="tag" href="/tags/nlp/">nlp</a><a class="link-muted mr-2" rel="tag" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/alipay.jpg" alt="Alipay"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/wechatpay.jpg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/12/18/%E5%A4%B4%E6%9D%A1%E5%AE%9E%E4%B9%A0%E6%80%BB%E7%BB%93-2019/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">头条实习总结-2019</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/11/24/Android%E7%9B%B8%E6%9C%BA%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91/"><span class="level-item">Android相机程序开发</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Michael Wang"></figure><p class="title is-size-4 is-block line-height-inherit">Michael Wang</p><p class="is-size-6 is-block">Android intern &amp; BUPT undergraduate</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">10</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Mrhwmichael/" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Mrhwmichael/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://weibo.com/u/2928617807?is_hot=1"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Linkedin" href="https://www.linkedin.com/in/%E6%98%8A%E5%AE%87-%E7%8E%8B-b3645a16b/"><i class="fab fa-linkedin"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://www.codesheep.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">程序羊的Blog</span></span><span class="level-right"><span class="level-item tag">www.codesheep.cn</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://morvanzhou.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">莫烦Python</span></span><span class="level-right"><span class="level-item tag">morvanzhou.github.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://www.jianshu.com/u/203b606b956c" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">厘米姑娘简书</span></span><span class="level-right"><span class="level-item tag">www.jianshu.com</span></span></a></li></ul></div></div></div><!--!--><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-12T14:00:04.000Z">2020-08-12</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/12/gradle%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/">gradle插件开发快速上手</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-01T03:12:58.000Z">2020-08-01</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/01/flutter-%E5%AD%A6%E4%B9%A0/">flutter 学习</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-07-01T10:19:39.000Z">2020-07-01</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/01/%E5%A4%B4%E6%9D%A1%E5%AE%9E%E4%B9%A0-2020%E4%B8%8A%E5%8D%8A%E5%B9%B4%E6%80%BB%E7%BB%93/">头条实习-2020上半年总结</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-07T03:32:14.000Z">2020-06-07</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/07/%E4%BB%8E%E6%98%A5%E8%8A%82%E6%B4%BB%E5%8A%A8%E7%9C%8B%E4%BA%92%E8%81%94%E7%BD%91app%E5%8F%91%E5%B1%95/">从春节活动看互联网app发展</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-01-16T09:48:41.000Z">2020-01-16</time></p><p class="title is-6"><a class="link-muted" href="/2020/01/16/%E7%AB%8B%E4%B8%AAFLAG/">立个FLAG</a></p><p class="is-uppercase"></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">August 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/01/"><span class="level-start"><span class="level-item">January 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/12/"><span class="level-start"><span class="level-item">December 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/11/"><span class="level-start"><span class="level-item">November 2019</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Android/"><span class="tag">Android</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Flag/"><span class="tag">Flag</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/blog/"><span class="tag">blog</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/flutter/"><span class="tag">flutter</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/gradle%E6%8F%92%E4%BB%B6/"><span class="tag">gradle插件</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/keras/"><span class="tag">keras</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp/"><span class="tag">nlp</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tensorflow/"><span class="tag">tensorflow</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%90%8E%E7%AB%AF/"><span class="tag">后端</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/"><span class="tag">字节跳动</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%9E%E4%B9%A0%E6%80%BB%E7%BB%93/"><span class="tag">实习总结</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%9E%E4%B9%A0%E7%BB%8F%E9%AA%8C/"><span class="tag">实习经验</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%A2%E6%88%B7%E7%AB%AF/"><span class="tag">客户端</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/"><span class="tag">插件开发</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%98%A5%E8%8A%82%E6%B4%BB%E5%8A%A8/"><span class="tag">春节活动</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B5%8B%E8%AF%95/"><span class="tag">测试</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9B%B8%E6%9C%BA/"><span class="tag">相机</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%84%E4%BB%B6%E5%8C%96/"><span class="tag">组件化</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="tag">自然语言处理</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0/"><span class="tag">跨平台</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="why&#039;s Blog" height="28"></a><p class="size-small"><span>&copy; 2020 Michael Wang</span>  </p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Mail to me" href="mailto:mr_hw@outlook.com"><i class="fab fa-paper-plane"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Theme by icarus" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://yoursite.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>
{"pages":[],"posts":[{"title":"使用Keras搭建NLP自然语言处理模型","text":"本篇博文承担了我在GitHub的开源代码的相关注解，这里给我的Github工程做一个简单的阐释。 代码话不多说，先放代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186# -*- coding：utf-8 -*-import jiebaimport refrom keras_preprocessing import sequenceimport numpy as npimport gensimimport tensorflow.keras as kerasfrom tensorflow.keras import layersimport csv# 配置相关维度，这里统一收敛到这里MAX_DOCUMENT_LEN = 300TRAINING_SIZE = 120000# 使用训练的word2Vec的词向量的配置myPath = 'ml_resources/Word2VecModel.vector'Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(myPath)EMBEDDING_SIZE = 128# 使用腾讯70000词的词向量的配置# myPath = 'ml_resources/70000_tencent.vector'# Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(myPath)# EMBEDDING_SIZE = 200# 构造包含所有词语的 list，以及初始化 “词语-序号”字典 和 “词向量”矩阵vocab_list = [word for word, Vocab in Word2VecModel.wv.vocab.items()] # 存储 所有的 词语word_index = {\" \": 0} # 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。 “词语-序号”字典word_vector = {} # 初始化`[word : vector]`字典# 初始化存储所有向量的大矩阵，留意其中多一位（首行），词向量全为 0，用于 padding补零。# 行数为所有单词数+1embeddings_matrix = np.zeros((len(vocab_list) + 1, Word2VecModel.vector_size))# 填充上述的字典和大矩阵for i in range(len(vocab_list)): # print(i) word = vocab_list[i] # 每个词语 word_index[word] = i + 1 # 词语：序号 word_vector[word] = Word2VecModel.wv[word] # 词语：词向量 embeddings_matrix[i + 1] = Word2VecModel.wv[word] # 词向量矩阵# print(embeddings_matrix.shape)# print(word_index) # 查看大字典内容# 目前生成六个内容，分别是label标签，总评score，星级别star1，star2，star3def read_csv(filename): content = [] label = [] score = [] star1 = [] star2 = [] star3 = [] with open(filename, encoding='utf-8') as csvDataFile: csvReader = csv.reader((line.replace('\\0', '') for line in csvDataFile), delimiter=',') for row in csvReader: if len(row)&lt;5: print(row) else: content.append(row[0]) label.append(row[1]) score.append(row[2]) star1.append(row[3]) star2.append(row[4]) star3.append(row[5]) print(len(content)) np.random.seed(100) np.random.shuffle(content) np.random.seed(100) np.random.shuffle(label) np.random.seed(100) np.random.shuffle(score) np.random.seed(100) np.random.shuffle(star1) np.random.seed(100) np.random.shuffle(star2) np.random.seed(100) np.random.shuffle(star3) X = np.asarray(content[0:TRAINING_SIZE]) Y = np.asarray(label[0:TRAINING_SIZE], dtype=int) A = np.asarray(score[0:TRAINING_SIZE], dtype=int) B = np.asarray(star1[0:TRAINING_SIZE], dtype=int) C = np.asarray(star2[0:TRAINING_SIZE], dtype=int) D = np.asarray(star3[0:TRAINING_SIZE], dtype=int) return X, Y, A, B, C, DX_train, Y_train, score, star1, star2, star3 = read_csv('ml_resources/training_data_set.csv')print(Y_train.mean()) # 统计数据集中1的占比behavior_input = np.concatenate((score.reshape(-1,1), star1.reshape(-1,1), star2.reshape(-1,1), star3.reshape(-1,1)), axis=1)print(behavior_input)# X_test, Y_test = read_csv('little_test.csv')def tokenizer(texts, word_index): data = [] maxnum = MAX_DOCUMENT_LEN for sentence in texts: new_txt = [] sentence = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&amp;*（）]+\", \"\", sentence) sentence = jieba.lcut(sentence) # print(sentence) i = 0 for word in sentence: i += 1 # print(word) try: new_txt.append(word_index[word]) except: new_txt.append(0) # print(new_txt) if i &gt; maxnum: # print(new_txt) maxnum = i data.append(new_txt) texts = sequence.pad_sequences(data, maxlen=MAX_DOCUMENT_LEN) print('{} {}'.format('max', maxnum)) return textsX_train = tokenizer(X_train, word_index)# 打乱np.random.seed(100)np.random.shuffle(X_train)np.random.seed(100)np.random.shuffle(Y_train)print(X_train)print(Y_train)print(X_train.shape, ' ', Y_train.shape)# 主训练模型部分input1 = keras.Input(shape=(MAX_DOCUMENT_LEN,))embedding = layers.Embedding(len(word_index), EMBEDDING_SIZE, input_length=MAX_DOCUMENT_LEN, embeddings_initializer=keras.initializers.Constant(embeddings_matrix))(input1)# 使用RNN模型训练部分（结果为x）x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(embedding)x = layers.Bidirectional(layers.LSTM(64))(x)x = layers.Dense(64, activation='relu')(x)x = layers.Dense(1, activation='sigmoid')(x)# 使用CNN模型训练部分（结果为y）filters = 250kernel_size = 3hidden_dims = 250max_features = 400000## y = layers.Dropout(0.2)(embedding)# y = layers.Conv1D(filters,# kernel_size,# padding='valid',# activation='relu',# strides=1)(y)# # we use max pooling:# y = layers.GlobalMaxPooling1D()(y)## # We add a vanilla hidden layer:# y = layers.Dense(hidden_dims)(y)# y = layers.Dropout(0.2)(y)# y = layers.Activation('relu')(y)## # We project onto a single unit output layer, and squash it with a sigmoid:# y = layers.Dense(1)(y)## # 连接CNN和RNN模型# input2 = keras.Input(shape=(1,))# x = keras.layers.concatenate([x, input2])# x = layers.Dense(2, activation='relu')(x)# output_tensor = layers.Dense(1, activation='sigmoid')(x)model = keras.Model(input1, x)model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.binary_crossentropy, metrics=['accuracy'])model.summary()# 模型可视化history = model.fit(X_train, Y_train, batch_size=128, epochs=5, validation_split=0.05, callbacks=[keras.callbacks.TensorBoard(log_dir='result')])model.save(\"TrainResult_full.h5\")","link":"/2019/11/27/%E4%BD%BF%E7%94%A8Keras%E6%90%AD%E5%BB%BANLP%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/"},{"title":"Windows系统建立博客踩坑","text":"忙活了一个周末，终于完成了个人技术Blog的搭建，windows系统真的是苦不堪言，配置环境坑的一批，作为第一篇文章先简单的把这个周末使用hexo搭建个人博客的坑说一下。 首先要万分感谢程序羊的视频，虽然我网上参考了很多采坑记录，但是主线剧情还是看的 https://www.bilibili.com/video/av44544186/?spm_id_from=333.788.videocard.0 这一视频，如果是mac跟着这个视频做应该会如丝般顺滑。 支持要求使用hexo建立个人博客并部署到GitHub，需要git，node及hexo的支持。各位可以搜索配置git，将SSH private key同步到GitHub，这也将在之后我们远程部署博客使用上。 开始踩坑之后就是正文部分了，这里按照程序羊的视频的顺序来写一下我踩的坑 一： cnpm安装成功无法使用首先就是淘宝的镜像cnpm安装失效，具体现象是cnpm提示安装成功，之后输入cnpm提示 “不是内部或外部命令，也不是可运行的程序或批处理文件”，问题出自windows的环境配置上。 这里在linux上是不需要配置的，而在windows中需要在我的电脑-高级系统设置-环境变量-用户变量中配置npm的路径，在这个路径下也能找到cnpm。我上网查发现每个人的cnpm位置不完全相同，在运行cnpm安装时候会生成一个路径，使用该路径即可，我的路径是 C:\\Users\\xxx\\AppData\\Roaming\\npm 二：hexo init卡死这个问题现象是运行hexo init指令后，卡死在cloning某一个组件，这里目前没有找到很好的解决方法，由于我退出的时候会出现hexo exit相关的提示，说明并不是卡死，而只是速度慢，通过漫长的等待最终我clone成功了，这里小伙伴们如果实在等的漫长看别人好像更换过镜像，可以在别的地方将hexo克隆下来 三：hexo d之后打不开个人博客在hexo d之后直接通过仓库地址打不开博客，这里我是通过GitHub的Environment中 View Deployment找到自己的博客地址的，如果实在无法打开可以尝试这个位置 hexo常用命令后面附带一下hexo的常用命令，供大家编辑博客之后参考。 1 清除hexo缓存1hexo clean 2 生成hexo相对应文件使用hexo generate，指令为 1hexo g 3 将我们的博客部署到远端使用hexo deploy，指令为 1hexo d 4 在本地预览一下博客的内容1hexo s 这样使用生成的地址： http://localhost:4000 就能预览我们的博客了 5 生成新的Post博客1hexo new &quot;My New Post&quot;","link":"/2019/11/17/Windows%E5%BB%BA%E7%AB%8B%E5%8D%9A%E5%AE%A2%E8%B8%A9%E5%9D%91/"},{"title":"头条实习2020","text":"先贴一个文章，很多小伙伴初入安卓不知道需要知道哪些内容，本着入门即精通的原则，我推荐以下文章 https://juejin.im/post/5c8b1bd56fb9a049e12b1692#heading-10 这篇文章提到了安卓需要的各种相关知识点，涉及较深内容，例如ASM插桩，gradle插件构建等安卓进阶技能 另外欢迎大家投递头条相关职位，我贴出来个我的个人邮箱：wanghaoyu.michael@bytedance.com 大家可以直接简历发给我，我们直接联系 最近期末考试结束了，我也回到公司继续码代码了，这次回来年前主要完成的是集群打包相关的东西，这里涉及了Docker容器相关的部署，Docker所提供 并且最近还准备进行go语言的学习，因为在写一个简单的独立灰度后端反馈功能，目前也是在语言学习的阶段，后续争取出个相关的文档和大家交流。","link":"/2020/01/26/%E5%A4%B4%E6%9D%A1%E5%AE%9E%E4%B9%A02020/"},{"title":"从春节活动看互联网app发展","text":"引言移动互联网时代，各个互联网公司都开始进行自己的活动从而取得流量，例如双十一，双十二等等，而其中刚刚过去的春节活动则是一年中参与人数最多，活动力度最大的活动之一。各个互联网公司也都是卯足了劲，前有支付宝五福分五亿，后有快手十亿红包。从2015年互联网公司首次和春节联欢晚会一起做活动开始，每一年春节活动都能吸引几十亿的流量，春节活动会给我们带来哪些技术难题？存在哪些难以克服的技术壁垒？我们所知的大厂又是使用哪些策略如何克服这些问题？本篇论文我将从以下三点来分析进行春节活动的技术难题及解决方案。 如何保证活动（入口、页面、链接）的动态下发及动态更新？2015年的时候，参加春节活动都需要更新到最新的app版本才可以展现，而今年我们会发现即使没有更新，到了某个时间节点后支付宝或者淘宝会自动显示出某个活动入口tab，这个又是如何做到的？而且在ios、安卓等多个系统中页面高度一致，这又是如何实现的？ 如何应对红包雨等瞬时流量激增带来的后端QPS压力？我们都知道，平时的服务端请求数量是比较稳定的。但是在支付宝和百度客户端的抢红包业务场景中，这个请求将会数十倍激增的，我们也看到，每一次红包雨过后app通常都会锁定提现功能来减轻服务端的压力，那么除此之外，还有什么值得考虑的优化细节？ 如何设计风控策略，从而实现发放红包的安全性，防止刷取红包而造成损失？在抽取高额大奖的时候的权重计算策略又是如何的？在发放短板卡（例如支付宝中的“敬业福”）的策略又是如何？ 通过各种技术手段，以上所提到的技术难题都可以得到解决，因此我们也可以看到，近两年的春节活动明显要比之前丰富的多，不仅是原来的单一玩法，而且要稳定的多，例如支付宝集五福活动，已经不会出现前两天的扫福失败或者提现超时的情况。在我们享受日益增长且多元化的春节活动的时候，其背后的技术也在飞速迭代。这背后的实现是怎样的？本文将从互联网大厂的技术方案和已公开的技术报告进行分析论证。 春节活动简介在分析之前，首先要说一下春节的活动形式，可能读者并没有参与过春节活动。以支付宝为代表的APP春节通常都是在春节前10天左右展开收集卡片的预热活动，到除夕瓜分红包及抽取个别的大奖，再到后面的各种游戏活动。到了最近两年还开始出现了AR，分享好友加速等等新鲜玩法。在深入技术之前，这里我想先简单分析下，春节活动的收益究竟如何？我们每次都觉得春节活动似乎放出了很多钱，投入了几亿甚至近年来的十几亿成本，这个投入真的能取得对等的回报么？ 其实，从近年的百度、快手等app的数据可以看到，整个活动在拉新拉活上都极其有效，而且刺激用户提现绑卡，积累支付的用户群体，例如当年支付宝，十几天的活动就带来了上亿的新用户。我们如果把发出的几亿红包除以用户数，这个成本甚至不到一元，这个拉新成本是极低的。作为对比，现在拉到一个支付宝新用户至少能获得16.88元的红包，而小米、华为等厂商的预装app价格据说也涨到了10元。因此，相比这些拉新拉活方式，春节活动对于单个用户的ROI（投入产出比）是相当可观的，只是因为总量很大。 因此，在春节活动中，如何使用技术保障线上的稳定和app的体验就显得非常重要。下面我将简单的从客户端、服务端和风控三个方面展开分析春节活动中应用到的技术和这些技术背后的思考。 客户端在客户端的分析中，我将对两大难题：保证多个端（IOS、安卓、网页）一致的多端一致性和动态更新（定时更改页面资源）进行技术剖析。 多端一致很早之前，当IOS和安卓两大阵营还没有诞生的时候，所有的东西都呈现在网页上，因此只需要做前端就好。后面当IOS和安卓诞生的时候，众所周知，Android 应用采用 Java 编写，iOS 应用采用 Objective-C 编写，Web 端采用 HTML/CSS/JavaScript 编写，使用的技术栈有很大的差别。像春节活动这样对多端一致有着较高要求的开发，需要的成本也是极高的。很多公司为了节省人力仍然只完成前端，app就像个浏览器一样，在app中将APP中的页面的内容直接使用webView展示前端页面，使用JSBridge进行通信。但是这种体验并不友好，因为前端和app的交互存在很高的时延，因此许多公司就在探索体验更好的的多端一致性技术实现。 这种技术统称为跨端代码实现，近两年也十分火热。各大互联网公司为此都投入大量人力，也出现了各种跨平台技术框架，主要代表有Google的Flutter和FaceBook的React Native，实现了通用的UI和动画，使用一套代码就可以同时运行在安卓和ios上，可以保证安卓和IOS两端有着高度一致的页面和功能，也降低了开发的人力成本，这里我将对这两大技术进行简单的介绍。 React Native，使用JavaScript作为编程语言，是Facebook于2015年4月开源的跨平台移动应用开发框架。其使用JavaScript作为前端开发语言，在跨平台开发中可谓大放异彩。利用通用的web技术不仅能开发出网站，也可以开发手机端web应用和移动端应用程序，在Android、iOS、Web都可以快速应用。Flutter是以Dart语言编写，Flutter开发环境这一套的流程对于前端开发来说并不太友好，因为其使用谷歌自家的Dart语言，其语法特性体验更接近客户端。2017年5月Google I/O大会正式对外公布Flutter，到2018年12月发布Flutter1.0，引发全球大量的开发者和企业开始研究Flutter。Flutter的定位同样是多端一体化，但是以客户端为首，先将Android和iOS基本打通，再逐步向Web端渗透，右图中就是通过flutter实现的ios和安卓端的示例。 使用React Native和Flutter可以快速的打造一个多端相对一致的代码，体验也更接近原生，如今阿里巴巴、字节跳动已经广泛接入Flutter方案。我们也可以预见新的app项目，在没有历史代码迁移包袱的情况下，也会更多的采用类似的方案，实现高效的多端代码开发。 动态更新在近两年的纯洁活动中，很多功能是不需要用户手动触发更新，只需重启应用就可以生效。我们常常会在临近春节发现，支付宝的程序虽然没有更新，但是点进首页就出现了新春活动的banner。要实现这样的动态更新动态下发，主要有以下几个途径：服务端下发配置，插件加载，H5/小程序，热修复/热更新，下面将简单的对这几项技术进行介绍。 最简单的实现便是服务端下发配置，即在软件初始化的时候去服务端拉取配置信息，最早期的淘宝、支付宝中的推荐内容也是用类似的方式实现的。然而，当需要下发通用配置的时候，这种方式就显得有待优化。一方面服务端的请求压力比较高，另外在弱网等条件下会出现请求超时等种种问题，因此H5和热修复/热更新就应运而生了。 以微信为首的H5/小程序，通过官方公布的文档与相关语法结构不难看出，微信小程序的开发技术上是使用一种类似 React Native 的框架来保证程序的原生性和稳定性。React Native已经介绍，可以通过JS的代码来实现类似原生交互，因此这样的程序请求的网页数据可以完全保存在服务端，同时通过JSBridge等相关的类似组件和app进行通信，达到动态更新和交互的效果。然而，这样的体验始终不如原生交互来的直接，网页的交互必然要考虑到延迟等多种因素。 至于热更新，由于苹果全面禁止应用商店上架的应用动态更新其程序中的代码，这里只讨论安卓端。最常见的就是Robust和Tinker技术，实现诸如类替换，资源更新的效果。这里通常的逻辑是通过安卓安装包apk中的dex计算差异，生成一个patch.dex。在客户端加载类的时候会将这个dex中的类覆盖原apk中的类，从而实现热更新/热修复。 客户端小结总的来说，如果不是大公司具有较强技术沉淀的企业，小的团队很可能无法应用类似Robust和Tinker这类比较复杂的技术方案。像唯品会、多点这些app基本是以webview方案为主，使用RN实现多端一致和热修复，这也启发了我们中小团队在技术选型的时候可以先考虑React Native等跨平台技术，从而能更快的部署自己的代码到用户手中。 服务端微信2015年和春晚合作，最高服务端QPS达到1600万，2016年微信服务端最高QPS达到2100万，可以说这个QPS是除了中国头部互联网大厂以外很少有公司可以扛得住的瞬时流量。而且不仅流量大，在活动开始的时候流量峰值也很不确定，没有人能准确预估，因此会给网络带来极强的不确定性压力。当服务端顶不住压力的时候，最明显一个案例的就是微博中出现爆炸性娱乐新闻的时候，由于突发流量激增，应用的请求崩溃超时，很多用户的微博图片加载不出来，下拉无法刷新，如右图所示，这就是服务端的流量无法负载从而产生的后果。因此，服务端的程序稳定性和鲁棒性就显得十分重要。 首先在这里介绍一下服务端是如何顶住压力的。由于机房的搭建涉及到很复杂的技术方案，这里不进行很深入的对于集群、容器部署的介绍。我将简单的进行一些高并发请求方案的分析。常用的方案是缓存、降级和限流，除此之外机房也应该有容灾机制。每一家公司都会采用自己的保密方案，因此，我们就客观分析服务端在开发高并发系统时通用的三把利器：缓存、降级和限流。 缓存：缓存的目的是提升系统访问速度和增大系统处理容量降级：降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行限流：限流的目的是通过对并发访问/请求进行限速，或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务、排队或等待、降级等处理 对于我们讨论的春节活动，由于缓存和降级策略不能明显带来收益，主要以限流来保障服务端的稳定性。限流方式主要有漏桶算法和令牌桶算法，这里对这两个主流算法进行简单介绍。 漏桶算法• 到达的数据包或请求放置在漏桶中（请求或数据包缓存）漏桶有一定容量，当请求或者数据包到达时漏桶已经满漏，请求和数据包丢弃。 • 漏桶以固定速率漏出请求或数据包，平滑突发流量。 令牌桶算法• 产生令牌：周期性的以一定速率往令牌桶中增加令牌。如果桶中的令牌数达到桶容量，丢弃多余令牌。（一般会定时如100ms添加一次令牌，有些改进算法能实时计算添加令牌数） • 消耗令牌：接受请求或输入数据时会消耗桶中的令牌。以请求或消息为单位时，可以一次消耗一个令牌。在网络传输中，消耗令牌的数量可以根据数据包的大小决定。 • 是否通过：桶中的令牌 &gt;= 所需令牌 时，请求或者数据包通过，否则被限流。对于被限流的请求或者数据包，可以有不同的处理方式：1、直接丢弃；2、进队列等待； 3、可以通过，但需要做特殊标记在2016年的QCon大会，阿里巴巴介绍了阿里线上管控体系，其中主要使用了令牌桶算法来实现限流的目的，可以动态增加/减少令牌，从而对瞬时流量进行比较好的兼容。在双十一、双十二等场景中均有所运用。《亿级流量网站架构》一书中对高并发高流量的网站架构进行了深度分析，对这里感兴趣可以从此书中深入挖掘。 风控测试风控，顾名思义，就是控制风险，防止网络攻击的策略。由于春节红包涉及金钱交易，控制交易的风险就显得尤为重要，否则很可能造成公司的财务损失。因为风控不到位在互联网引起的bad case还是十分常见的，2019年1月20日，电商平台拼多多被曝出现重大BUG，用户可以领取100元无门槛优惠券，据页面显示，该优惠券有效期一年，且全场通用。这次事故中许多羊毛党直接将优惠券充话费，无法追回，给拼多多带来了上亿的损失。淘宝在2020年3月25日也曾爆出内测弹窗的bug，由于热更新模块在之后才加载，因此无法完全的修复，只能等用户覆盖安装，导致淘宝的口碑和用户流失问题。因此，一旦涉及互联网金融，风险控制、预警机制就显得尤为重要。 像老牌的互联网公司阿里，风控早已成为了一项基础设施建设，成为了交易安全的护城河。阿里业务安全智能风控平台，基于大数据实时分析建模技术，通过每个用户行为背后数千个数据指标的实时计算，利用规则引擎、模型引擎、关系网络、团伙分析、设备画像、语义分析、机器视觉等技术对风险进行快速有效的防控。大厂的研发通常会经过研发自测 -&gt; QA回归 -&gt; 版本灰度 -&gt; 正式上线的过程，通过测试将问题提前处理，而且具备周全的熔断机制。而且，阿里应对春节项目也有“时间穿越”来保障，构造出一个未来真实的环境，通过进入这个环境可以做到在真实的未来场景中进行测试和验收，并且通过流程化、卡口化的方式保证无遗漏，辅助自动化驱动，驱动过程数据采集以及问题分析，给出在真实场景下的测试结果。这样就能直接在客户端、服务端均模拟出春节活动的真实场景，从而测试。 在春节活动中，各大公司对于抽卡还有特殊的处理，这里我们简单的讨论下。我们首先考虑，在抽卡活动中，如何能够拿到抽到所有卡从而拿到红包。首先要了解抽卡的规则，在抽卡的过程中常常我们会遇到某一张卡抽不到，例如支付宝中的敬业福，我们可以暂且称之为稀有卡。前面也有提到，这里的稀有卡的发放策略，可以使用令牌桶算法。简单来说，这里的运用就是根据一定请求数量来放入令牌，达到某个阈值X就会发出一个稀有卡，并且去掉N个令牌。这样，就能精准的控制发稀有卡的数量，而且保证稀有卡发放是根据流量浮动的。 另一个问题就是对用户的判断。我们常常发现在淘宝抽卡之后，在支付宝登陆后app内会同步显示出来我们卡的数量，这是如何实现的呢？当然一种机制是验证是直接根据用户的uid来判断。但是当我们如果有一个App不是登陆状态呢？这里最常用的策略是根据一个设备的did（Android）/IDFA（IOS）来判断是否是同一个账号。根据行为数据生成用户画像，一旦存在潜在风险，用户就会进入风控黑名单，从而不会产生集齐卡片的效果。 总结近年来，我们可以看到春节活动、双十一、618等等狂欢活动越来越多，而且参与的用户人数也是屡创新高。可以明显的感觉到春节活动发展之快，近五年从原来的支付宝、微信到现在的百度、抖音、快手等等百家齐放。从之前的单一app的扫码到现在各种各样的花样AR活动，其背后的技术也在迅速的迭代，很多全新技术手段的落地也让我们体验到更流畅更丰富的内容。本文对春节活动背后的技术进行了简单的分析，很多大厂的保密“杀手锏”武器，如ios热更新等等作者也并不是十分了解，读者如果有兴趣可以关注美团技术团队、微信技术团队和国外的React Native、Google的官方渠道了解更多。 参考内容 HTTPS://WWW.IMOOC.COM/ARTICLE/283023 支付宝17年新春红包技术体系剖析 HTTPS://S3PLUS.MEITUAN.NET/V1/MSS_E63D09AEC75B41879DCB3069234793AC/FILE/%E5%89%8D%E7%AB%AF%E7%AF%87.PDF 美团点评2019技术年货-前端篇 HTTPS://JUEJIN.IM/ENTRY/56E7BB6D5BBB50004C259A83 从 0 到 1 构建美团压测工具 HTTPS://WWW.JIANSHU.COM/P/C02899C30BBD 漏斗算法和令牌桶算法的理解 HTTPS://BAIKE.BAIDU.COM/ITEM/令牌桶算法/6597000?FR=ALADDIN 令牌桶算法 HTTPS://JUEJIN.IM/POST/5A260C6AF265DA43294DE65A 微信朋友圈：应对春节千亿访问量背后的故事 HTTPS://BLOG.CSDN.NET/TAOBAOJISHU/ARTICLE/DETAILS/99830639 揭秘阿里测试技术最高奖项目——“时间穿越” HTTPS://PATENTS.GOOGLE.COM/PATENT/CN1536815A/ZH%EF%BC%89 华为专利 采用令牌漏桶进行报文限流的方法 HTTPS://LEARNKU.COM/DOCS/BUILD-WEB-APPLICATION-WITH-GOLANG/027-CONCURRENCY/3165 GO WEB编程 HTTPS://WWW.ZHIHU.COM/QUESTION/382359511 知乎 如何看待阿里S1级事故，淘宝3.25重大BUG问题？ HTTPS://JUEJIN.IM/POST/5BC41D80F265DA0AAA053CA5 蚂蚁金服MPAAS模块化方案","link":"/2020/06/07/%E4%BB%8E%E6%98%A5%E8%8A%82%E6%B4%BB%E5%8A%A8%E7%9C%8B%E4%BA%92%E8%81%94%E7%BD%91app%E5%8F%91%E5%B1%95/"},{"title":"Android相机程序开发","text":"前言这周末写了一个小型的相机app，具体实现功能就是冷启动的Splash-进到主屏幕，出现两个选项，一个是相机获取照片，一个是相册获取照片，点击后进入相机/相册，照相或选取照片，之后弹出照片确认页面。实现这样的一个小demo很简单，下面将简单的介绍这次的开发过程。 代码分析代码规划首先就是对代码进行一个简单的规划，实现这几个内容还是比较简单的，冷启动使用SplashActivity，主界面上放置两个按钮，相机和相册，并且在主界面上使用StartActivityForResult调用相机，这里由于操作比较少就不需要ContentProvider了，只需要声明权限就好。最后还需要一个PhotoEnsure来实现一个确认的效果。 代码实现权限声明下面就是代码的具体实现了，首先我们需要在根目录的AndroidManifest.xml文件中声明如下权限，放在Manifest的最开始就可以 12&lt;uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" /&gt;&lt;uses-permission android:name=\"android.permission.CAMERA\" /&gt; Splash对于Splash的实现，网上有很多的动画过渡实现参考，后续我将会把我的实现贴出来。 Main接下来就是最主要的——MainActivity了。话不多说，先看代码。 1234567891011121314151617181920212223 final Intent takePictureIntent = new Intent(MediaStore.ACTION_IMAGE_CAPTURE); final Intent choosePhotoIntent = new Intent(Intent.ACTION_PICK);/** * 从相机中获取照片 */ camera.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { startActivityForResult(takePictureIntent,REQUEST_FROM_CAMERA); } } ); /** * 从相册中获取照片 */ photo.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { startActivityForResult(choosePhotoIntent,REQUEST_FROM_PHOTO_BOOTH); } }); 这里就是对两个核心的按钮的事件监听器声明，点按后触发对应事件。startActivityForResult()对应的就是当前Activity中的onActivityResult()方法，其中的data就是我们想要获取的内容，因此需要复写这个方法，复写如下 12345678910111213141516171819202122232425262728 @Override protected void onActivityResult(int requestCode, int resultCode, @Nullable Intent data) { super.onActivityResult(requestCode, resultCode, data); Intent ensurePhotoIntent = new Intent(MainActivity.this,PhotoEnsureActivity.class); Bitmap photoSelected = null; // 从相册中获得数据 if(requestCode == REQUEST_FROM_PHOTO_BOOTH){ try{ photoSelected = MediaStore.Images.Media.getBitmap(getContentResolver(),data.getData()); }catch (Exception e){ e.printStackTrace(); } } // 从相机中获得数据 if(requestCode == REQUEST_FROM_CAMERA){ photoSelected = data.getExtras().getParcelable(\"data\"); } // 容错 if(data != null){ ensurePhotoIntent.putExtra(\"photo_selected\",photoSelected); startActivity(ensurePhotoIntent); }else{ Toast.makeText(this, \"获取图片失败，请重试\", Toast.LENGTH_SHORT).show(); } }} 这里就体现出来相机和相册的差异性，相机可以直接从data中获得Bitmap类的图片，而相册并不行，需要通过MediaStore来获取，因为返回的是照片的Uri。这样我们合并两种方式的结果到photoSelected中，最后将Bitmap类型的数据放入Bundle，对应键值对（”photo_selected”, photoSelected） ensureensure主要承担了显示一个确认页的功能，通过以下代码提取bundle中的bitmap图片并展示出来 123Bitmap bm = this.getIntent().getParcelableExtra(\"photo_selected\");ImageView img = findViewById(R.id.photo_selected);img.setImageBitmap(bm);","link":"/2019/11/24/Android%E7%9B%B8%E6%9C%BA%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91/"},{"title":"头条实习总结-2019","text":"引言好久不见，这段时间一直没有更新个人博客是因为期末考试各种烦人的事情，现在也是回到头条继续快乐工作了。其实一直也没有对整个实习过程做一个很好的总结，这篇博文就简单的总结下我去年8月到10月三个月的实习所涉及的工作相关内容，并且形成一个技术交流性质的总结文档。 废话不多说，我们开始吧，我的总结将主要包括以下几个方面——安卓开发，平台架构，研发效率，这也是我在2019年工作中主要做的事情 安卓开发小结这里安卓开发之前也有过一篇文章我谈到安卓开发的一个相机小demo，这里其实这个demo只是简单地调用了相机资源，相册资源，非常适合初学的朋友们模仿。由于我本身在加入头条前并没有安卓相关的实战经验，所以对安卓的虚拟机，aar包和各种库SDK的调用非常不熟悉，还记得第一周周会的时候，我基本上都用来了解dex是什么了。。。。当时探讨如何判断一个方法或者类要不要打入maindex的问题，我连为什么要打maindex（64K方法数限制）都不知道。。。。并且由于所学专业的原因，其实我对Java的编程经验也不是很深，很多并发问题并不知道解法，还不能控制好线程。 因此，到了头条的小白我就只能从0学起，这里还是祭出一张技能树的大图，来源见水印 如果这些都完全理解了，我认为找到个工作是肯定没问题的。还是推荐几本安卓相关的书，如果是对Java开发一无所知的就请把Thinking in Java这本书加入购物车，如果对 当然，距离实战还是有距离的，为什么这么说，就是因为实际的情况远比这些技能树复杂，就像我刚才所说的，实际我们在编写程序的时候很难出现dex方法数受限的情况，因为我们写的demo很少涉及这个问题，我们也不需要在Splash阶段开多个异步线程加载资源，因为我们后端可能根本不会下发多少资源。而且，在自己编码的时候也很少用到CI持续集成，因为我们自己写的demo不会涉及版本发布问题，至于热修复。。。我们写的小demo根本没有迭代周期和崩溃统计，因此当然也就不会涉及 平台架构小结这里主要说一下当一个工程变大之后涉及哪些变化，对了，这里还要mark一篇博文，来教教大家如何快速的上手git，抓取代码从而进行多人合作。常见的方式就是svn和git，我将简单的写一下git的操作指南，争取达到十分中内快速上手。最近上班比较忙，可能要拖到春节后完成了 研发效率小结研发效率就是我在头条这段时间比较着重开发的了，我们通过Android Studio完成了轻量插件以实现RD的研发效率提升。目前很多同类APP客户端由于工程浩大业务繁杂，都会存在多仓开发的情况，并且仓库间存在依赖，难以解耦，因此存在一个需求涉及多个代码仓库的MR提交。我们希望通过多仓插件来进行多个代码仓库的MR提交，能够跑通我们的合码流程（Gitlab-CI），我们还有同学在处理预编译，编写脚本来完成lint代码检查，包大小检查，发布release包等，这样我们的研发流程就能跑通了。 至此，我的2019年实习告一段落，我也回北邮开始准备自己的期末考试，2020年寒假将会继续实习，期待到时候再见！ 相关链接推荐编程，一定是在不断学习的过程中不断提升，这里我mark几个对我很有帮助的文章 ①首先推荐的是厘米姑娘的安卓开发相关文章，正式砍了她的实习经历才让我意识到一个安卓开发工程师是如何一步步成长起来的，也就有了现在我的博客。她的简书链接： https://www.jianshu.com/u/203b606b956c ②第二个推荐的就是程序羊，他的视频介绍了很多程序猿实战的应用，感兴趣的可以进去听一下 https://space.bilibili.com/384068749?from=search&amp;seid=9897226057628769700 ③第三个就是推荐论坛了，掘金里面真的有非常丰富的编程资源，有适合新手的也有适合专家的，大家可以去搜相关的文章看，想要获取比较前沿的技术文档可以参考以下美团技术文章，这里我摘取了前端篇，供大家学习交流，里面也是干货满满 https://s3plus.meituan.net/v1/mss_e63d09aec75b41879dcb3069234793ac/file/%E5%89%8D%E7%AB%AF%E7%AF%87.pdf","link":"/2019/12/18/%E5%A4%B4%E6%9D%A1%E5%AE%9E%E4%B9%A0%E6%80%BB%E7%BB%93-2019/"},{"title":"立个FLAG","text":"Flag篇这篇文章纯粹因为本人平时效率较低，因此准备给自己立几个学习flag 前端方面准备学习使用antd或者eleme开源组件库，使用vue架构搭建前端 安卓开发方面我已经看过《第一行代码》，《app研发录》，后续会看安卓开发艺术探索来提升一下自己，这个顺序也是我推荐给刚入门的安卓萌新快速上手的。并且最好自己做一些项目，虽然可能不涉及企业级的合码流程，持续集成，但是对于基本的安卓虚拟机，安卓组件还是能够有所了解的 对于java开发，我之前的基础也比较的弱，现在自己也准备开始补起来了，初步准备先啃四大名著的前两本-Thinking in Java和Effective Java，重新把基本的东西强化一下","link":"/2020/01/16/%E7%AB%8B%E4%B8%AAFLAG/"}],"tags":[{"name":"keras","slug":"keras","link":"/tags/keras/"},{"name":"tensorflow","slug":"tensorflow","link":"/tags/tensorflow/"},{"name":"nlp","slug":"nlp","link":"/tags/nlp/"},{"name":"自然语言处理","slug":"自然语言处理","link":"/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"字节跳动","slug":"字节跳动","link":"/tags/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/"},{"name":"实习经验","slug":"实习经验","link":"/tags/%E5%AE%9E%E4%B9%A0%E7%BB%8F%E9%AA%8C/"},{"name":"春节活动","slug":"春节活动","link":"/tags/%E6%98%A5%E8%8A%82%E6%B4%BB%E5%8A%A8/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"flutter","slug":"flutter","link":"/tags/flutter/"},{"name":"相机","slug":"相机","link":"/tags/%E7%9B%B8%E6%9C%BA/"},{"name":"实习总结","slug":"实习总结","link":"/tags/%E5%AE%9E%E4%B9%A0%E6%80%BB%E7%BB%93/"},{"name":"插件开发","slug":"插件开发","link":"/tags/%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/"},{"name":"Flag","slug":"Flag","link":"/tags/Flag/"}],"categories":[]}